{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posthoc Laplace Approximation with EuroSAT100 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all implemented UQ-methods are just lightning modules that can take in any underlying model you might have, it is straightforward to apply them to a wide array of use cases. So let's to that for a classification task on the EuroSAT100 dataset, a dataset of Sentinel-2 imagery with 13 spectral bands and 10 classes. We will use the [TorchGeo Library](https://torchgeo.readthedocs.io/en/stable/api/datasets.html#eurosat) to handle the data loading for us. In this case we will use the Laplace Approximation as a post-hoc method to equip a pretrained network with a notion of uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import timm\n",
    "from functools import partial\n",
    "import torch\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "from torchgeo.datamodules import EuroSAT100DataModule\n",
    "from torchgeo.trainers import ClassificationTask\n",
    "from torchgeo.models import ResNet18_Weights\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "from lightning_uq_box.uq_methods import LaplaceClassification\n",
    "from laplace import Laplace\n",
    "from lightning_uq_box.viz_utils import plot_training_metrics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datmodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(tempfile.gettempdir(), \"eurosat100\")\n",
    "datamodule = EuroSAT100DataModule(\n",
    "    root=root, batch_size=batch_size, num_workers=num_workers, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model and Training\n",
    "\n",
    "We will use pretrained weights from TorchGeo which can be loaded into a [timm](https://github.com/huggingface/pytorch-image-models) model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ResNet18_Weights.SENTINEL2_ALL_MOCO\n",
    "task = ClassificationTask(\n",
    "    model=\"resnet18\",\n",
    "    loss=\"ce\",\n",
    "    weights=weights,\n",
    "    in_channels=13,\n",
    "    num_classes=10,\n",
    "    learning_rate=0.001,\n",
    "    learning_rate_schedule_patience=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nils/.local/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/nils/.conda/envs/uqboxEnv/lib/python3.9/site-p ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | ResNet           | 11.2 M\n",
      "1 | loss          | CrossEntropyLoss | 0     \n",
      "2 | train_metrics | MetricCollection | 0     \n",
      "3 | val_metrics   | MetricCollection | 0     \n",
      "4 | test_metrics  | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.852    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 4/4 [00:00<00:00,  4.59it/s, v_num=2]            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 4/4 [00:01<00:00,  3.70it/s, v_num=2]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=1,\n",
    "    logger=CSVLogger(root),\n",
    "    log_every_n_steps=1,\n",
    "    devices=[0],\n",
    "    accelerator=\"gpu\",\n",
    ")\n",
    "\n",
    "trainer.fit(task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we will setup a Laplace Approximation model with the [Laplace](https://github.com/AlexImmer/Laplace) package. In this case we will use a last-layer approximation, but check their [documentation](https://aleximmer.github.io/Laplace/) to see the different possible configurations. The lightning-uq-box simply provides a wrapper so you can stay within the lightning modelling framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = Laplace(task.model, likelihood=\"classification\", subset_of_weights=\"last_layer\")\n",
    "\n",
    "laplace_model = LaplaceClassification(model=la)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different datasets might have different conventions about what inputs and targets are called, especially across domains and tasks. By default lightning-uq-box expects a batch with dictionary keys \"inputs\" and \"targets\", however, these attributes can be changed as follows. The EuroSAT100 dataset has keys \"image\" and \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_model.input_key = \"image\"\n",
    "laplace_model.target_key = \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Laplace and make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/SSD2/nils/lightning-uq-box/docs/tutorials/earth_observation/laplace_eurosat100.ipynb Cell 17\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226d6c34656f536572766572227d/mnt/SSD2/nils/lightning-uq-box/docs/tutorials/earth_observation/laplace_eurosat100.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226d6c34656f536572766572227d/mnt/SSD2/nils/lightning-uq-box/docs/tutorials/earth_observation/laplace_eurosat100.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     logger\u001b[39m=\u001b[39mCSVLogger(root),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226d6c34656f536572766572227d/mnt/SSD2/nils/lightning-uq-box/docs/tutorials/earth_observation/laplace_eurosat100.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     log_every_n_steps\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226d6c34656f536572766572227d/mnt/SSD2/nils/lightning-uq-box/docs/tutorials/earth_observation/laplace_eurosat100.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     devices\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226d6c34656f536572766572227d/mnt/SSD2/nils/lightning-uq-box/docs/tutorials/earth_observation/laplace_eurosat100.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226d6c34656f536572766572227d/mnt/SSD2/nils/lightning-uq-box/docs/tutorials/earth_observation/laplace_eurosat100.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226d6c34656f536572766572227d/mnt/SSD2/nils/lightning-uq-box/docs/tutorials/earth_observation/laplace_eurosat100.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m datamodule\u001b[39m.\u001b[39msetup(\u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# give access to training dataloader used to fit laplace\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226d6c34656f536572766572227d/mnt/SSD2/nils/lightning-uq-box/docs/tutorials/earth_observation/laplace_eurosat100.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtest(laplace_model, datamodule\u001b[39m=\u001b[39;49mdatamodule)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:742\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m    741\u001b[0m _verify_strategy_supports_compile(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[0;32m--> 742\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    743\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule\n\u001b[1;32m    744\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:785\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(model, test_dataloaders\u001b[39m=\u001b[39mdataloaders, datamodule\u001b[39m=\u001b[39mdatamodule)\n\u001b[1;32m    782\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    783\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn, ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    784\u001b[0m )\n\u001b[0;32m--> 785\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    786\u001b[0m \u001b[39m# remove the tensors from the test results\u001b[39;00m\n\u001b[1;32m    787\u001b[0m results \u001b[39m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:1016\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mbarrier(\u001b[39m\"\u001b[39m\u001b[39mrun-stage\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluating:\n\u001b[0;32m-> 1016\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1017\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1018\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning/pytorch/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning/pytorch/loops/evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m     previous_dataloader_idx \u001b[39m=\u001b[39m dataloader_idx\n\u001b[1;32m    114\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx)\n\u001b[1;32m    116\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning/pytorch/loops/evaluation_loop.py:376\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    375\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 376\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39;49mstep_kwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    378\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    380\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_test_batch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mon_validation_batch_end\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:294\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 294\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    296\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    297\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.test_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtest_step_context():\n\u001b[1;32m    402\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TestStep)\n\u001b[0;32m--> 403\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtest_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/SSD2/nils/lightning-uq-box/lightning_uq_box/uq_methods/laplace_model.py:182\u001b[0m, in \u001b[0;36mLaplaceBase.test_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_step\u001b[39m(\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39m, batch: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Tensor], batch_idx: \u001b[39mint\u001b[39m, dataloader_idx: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Test step.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     out_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_step(batch[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_key])\n\u001b[1;32m    183\u001b[0m     out_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_key] \u001b[39m=\u001b[39m (\n\u001b[1;32m    184\u001b[0m         batch[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_key]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    185\u001b[0m     )\n\u001b[1;32m    187\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\n\u001b[1;32m    188\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtest_loss\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    189\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(out_dict[\u001b[39m\"\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m\"\u001b[39m], batch[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_key]\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)),\n\u001b[1;32m    190\u001b[0m     )  \u001b[39m# logging to Logger\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/SSD2/nils/lightning-uq-box/lightning_uq_box/uq_methods/laplace_model.py:335\u001b[0m, in \u001b[0;36mLaplaceClassification.predict_step\u001b[0;34m(self, X, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39minference_mode(\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    331\u001b[0m     \u001b[39m# inference tensors are not saved for backward so need to create\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     \u001b[39m# a clone with autograd enables\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mclone()\u001b[39m.\u001b[39mrequires_grad_()\n\u001b[0;32m--> 335\u001b[0m     probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    337\u001b[0m     entropy \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39msum(probs \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mlog(probs), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    339\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m\"\u001b[39m: probs, \u001b[39m\"\u001b[39m\u001b[39mpred_uct\u001b[39m\u001b[39m\"\u001b[39m: entropy}\n",
      "File \u001b[0;32m/mnt/SSD2/nils/lightning-uq-box/lightning_uq_box/uq_methods/laplace_model.py:120\u001b[0m, in \u001b[0;36mLaplaceBase.forward\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlaplace_fitted:\n\u001b[1;32m    118\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_test_start()\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(X)\n",
      "File \u001b[0;32m~/.conda/envs/uqboxEnv/lib/python3.9/site-packages/laplace/baselaplace.py:530\u001b[0m, in \u001b[0;36mParametricLaplace.__call__\u001b[0;34m(self, x, pred_type, link_approx, n_samples)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnsupported link approximation \u001b[39m\u001b[39m{\u001b[39;00mlink_approx\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    529\u001b[0m \u001b[39mif\u001b[39;00m pred_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mglm\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 530\u001b[0m     f_mu, f_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_glm_predictive_distribution(x)\n\u001b[1;32m    531\u001b[0m     \u001b[39m# regression\u001b[39;00m\n\u001b[1;32m    532\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlikelihood \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mregression\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/uqboxEnv/lib/python3.9/site-packages/laplace/lllaplace.py:118\u001b[0m, in \u001b[0;36mLLLaplace._glm_predictive_distribution\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_glm_predictive_distribution\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m--> 118\u001b[0m     Js, f_mu \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackend\u001b[39m.\u001b[39;49mlast_layer_jacobians(X)\n\u001b[1;32m    119\u001b[0m     f_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunctional_variance(Js)\n\u001b[1;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m f_mu\u001b[39m.\u001b[39mdetach(), f_var\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/.conda/envs/uqboxEnv/lib/python3.9/site-packages/laplace/curvature/curvature.py:79\u001b[0m, in \u001b[0;36mCurvatureInterface.last_layer_jacobians\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlast_layer_jacobians\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     65\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute Jacobians \\\\(\\\\nabla_{\\\\theta_\\\\textrm{last}} f(x;\\\\theta_\\\\textrm{last})\\\\) \u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m    only at current last-layer parameter \\\\(\\\\theta_{\\\\textrm{last}}\\\\).\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m        output function `(batch, outputs)`\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     f, phi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward_with_features(x)\n\u001b[1;32m     80\u001b[0m     bsize \u001b[39m=\u001b[39m phi\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     81\u001b[0m     output_size \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/uqboxEnv/lib/python3.9/site-packages/laplace/utils/feature_extractor.py:63\u001b[0m, in \u001b[0;36mFeatureExtractor.forward_with_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_with_features\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m     54\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward pass which returns the output of the penultimate layer along\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m    with the output of the last layer. If the last layer is not known yet,\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    it will be determined when this function is called for the first time.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39m        one batch of data to use as input for the forward pass\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(x)\n\u001b[1;32m     64\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_features[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_layer_name]\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m out, features\n",
      "File \u001b[0;32m~/.conda/envs/uqboxEnv/lib/python3.9/site-packages/laplace/utils/feature_extractor.py:50\u001b[0m, in \u001b[0;36mFeatureExtractor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_last_layer(x)\n\u001b[1;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     \u001b[39m# if last and penultimate layers are already known\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.conda/envs/uqboxEnv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/uqboxEnv/lib/python3.9/site-packages/timm/models/resnet.py:730\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 730\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_features(x)\n\u001b[1;32m    731\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_head(x)\n\u001b[1;32m    732\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/uqboxEnv/lib/python3.9/site-packages/timm/models/resnet.py:709\u001b[0m, in \u001b[0;36mResNet.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_features\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 709\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    710\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m    711\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact1(x)\n",
      "File \u001b[0;32m~/.conda/envs/uqboxEnv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/uqboxEnv/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.conda/envs/uqboxEnv/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger=CSVLogger(root), log_every_n_steps=1, devices=[0], accelerator=\"gpu\"\n",
    ")\n",
    "datamodule.setup(\"fit\")  # give access to training dataloader used to fit laplace\n",
    "trainer.test(laplace_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(datamodule.test_dataloader()))\n",
    "preds = laplace_model.predict_step(sample[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 10]), torch.Size([16]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[\"pred\"].shape, preds[\"pred_uct\"].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uqboxEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
