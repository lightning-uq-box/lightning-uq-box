uq_method:
  _target_: lightning_uq_box.uq_methods.VAE
  model:
    _target_: torchseg.Unet
    encoder_name: tiny_vit_11m_224
    encoder_weights: imagenet
    classes: 1 # number of channels for reconstruction loss
    in_channels: 3
    encoder_depth: 3
    decoder_channels: [128, 64, 32]
    encoder_params:  # additional params passed to timm.create_model and the vit encoder
      scale_factors: [2, 1, 0.5]
      # img_size: 224
    head_upsampling: 2
  latent_size: 10
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.003

data:
  _target_: lightning_uq_box.datamodules.ToyPixelwiseRegressionDataModule
  image_size: 224